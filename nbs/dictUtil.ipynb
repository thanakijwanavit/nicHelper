{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dictUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import yaml\n",
    "from beartype import beartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def printDict(d: dict, length: int = 10, space=0):\n",
    "    \"\"\"\n",
    "    print dictionary as first length value of values \\n\n",
    "    d: dict: the dictionary to be printed \\n\n",
    "    length: int: if the value is a string, then it will print the first length letter of the value, default = 10 \\n\n",
    "    space: int: the amount of additional space to be added for each nested dictionary, default = 0\n",
    "    \"\"\"\n",
    "    if type(d) != dict:\n",
    "        print(\"this is not a dict\")\n",
    "        print(d)\n",
    "    else:\n",
    "        for k, v in d.items():\n",
    "            if type(v) == dict:\n",
    "                print(f\"{' '*space}{k}\")\n",
    "                printDict(v, space=space + 1)\n",
    "            else:\n",
    "                print(f\"{' '*space}{k} : {v[:length] if type(v)==str else v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key : sjfhdkljha\n",
      "nestedKey\n",
      " nestedKey2 : 9380238408\n",
      " nested3\n",
      "  nested4 : hello\n"
     ]
    }
   ],
   "source": [
    "printDict(\n",
    "    {\n",
    "        \"key\": \"sjfhdkljhafsdlkjhdfaslkjhkljfadshklhfa\",\n",
    "        \"nestedKey\": {\"nestedKey2\": \"938023840843\", \"nested3\": {\"nested4\": \"hello\"}},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def allKeysInDict(inputDict: dict, keys: list):\n",
    "    \"\"\"\n",
    "    checks whether all the keys given in the list are also keys in the inputDict dictionary \\n\n",
    "    inputDict: dict: the dictionary that will be used to check whether all the keys are in this dictionary \\n\n",
    "    keys: list: the list of keys\n",
    "    \"\"\"\n",
    "    return all(key in inputDict for key in keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "inputDict = {\"user\": \"nic\", \"phone\": \"+66816684442\", \"pw\": \"12345678\", \"name\": \"nic\"}\n",
    "passingKeys = [\"user\", \"phone\", \"pw\"]\n",
    "failedKeys = [\"us\", \"phone\"]\n",
    "print(allKeysInDict(inputDict, passingKeys))\n",
    "print(allKeysInDict(inputDict, failedKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def filterDt(dtDict: dict):\n",
    "    \"\"\"\n",
    "    convert unjsonable datetime object to timestamp in the dictionary, this works for nested dictionary as well \\n\n",
    "    dtDict: dict: the dictionary inputted to convert the datetime object of its value\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "\n",
    "    return {\n",
    "        k: (\n",
    "            (filterDt(v) if type(v) == dict else v)\n",
    "            if type(v) != datetime\n",
    "            else v.timestamp()\n",
    "        )\n",
    "        for k, v in dtDict.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': {'time2': 1618763407.18315}, 'hello': 'world'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "filterDt({\"time\": {\"time2\": datetime.now()}, \"hello\": \"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def stripDict(data: dict):\n",
    "    \"\"\"\n",
    "    if the value in the dictionary is a string, it will 'strip' the value to make it more clear \\n\n",
    "    data: dict: the dictionary inputted to be 'stripped'\n",
    "    \"\"\"\n",
    "    return {k: v.strip() if type(v) == str else v for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sdfd': 'dsf', 'gdsgsa  ': 234}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripDict({\"sdfd\": \"dsf  \", \"gdsgsa  \": 234})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import hashlib, pickle, base64\n",
    "\n",
    "\n",
    "def hashDict(data: dict, hasher=hashlib.sha1(), encoder=pickle.dumps):\n",
    "    \"\"\"\n",
    "    hashes the dictionary inputted \\n\n",
    "    data: dict: the dictionary inputted to be 'hashed'\n",
    "    \"\"\"\n",
    "    hasher.update(encoder(data))\n",
    "    rawHash = hasher.digest()\n",
    "    return base64.b64encode(rawHash).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 µs, sys: 6 µs, total: 43 µs\n",
      "Wall time: 47.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DJ0JD7FLbd/e7NfdvLcRXbJGa8w='"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hashDict({'hello':'world'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pickle\n",
    "\n",
    "\n",
    "def saveDictToFile(data: dict, path: str):\n",
    "    \"\"\"\n",
    "    saves the dictionary to the file directed by the path \\n\n",
    "    data: dict: the dictionary to be saved \\n\n",
    "    path: str: the file path to the file the dictionary is going to be saved\n",
    "    \"\"\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def loadDictFromFile(path: str):\n",
    "    \"\"\"\n",
    "    returns the dictionary that is saved in the file \\n\n",
    "    path: str: the path taken to the file of the dictionary\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'test'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveDictToFile({\"test\": \"test\"}, \"/tmp/testdict\")\n",
    "loadDictFromFile(\"/tmp/testdict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def saveStringToFile(data: str, path: str):\n",
    "    \"\"\"\n",
    "    saves the string to the file directed by the path \\n\n",
    "    data: str: the string to be saved \\n\n",
    "    path: str: the file path to the file the string is going to be saved\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "\n",
    "def loadStringFromFile(path: str):\n",
    "    \"\"\"\n",
    "    returns the string that is saved in the file \\n\n",
    "    path: str: the path taken to the file of the string\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/tmp/teststr\"\n",
    "saveStringToFile(\"hello\", path)\n",
    "loadStringFromFile(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def genSchema(inputDict: dict, format_=\"yaml\") -> (dict, str):\n",
    "    \"\"\"\n",
    "    generate a json schema from dict \\n\n",
    "    format: return schema in json or yaml, 'both' can be inputted to return a tuple of (json, yaml), output = dict or str, default = 'yaml' \\n\n",
    "    inputDict: dict: the dict inputted to be used to generate the schema\n",
    "    \"\"\"\n",
    "    from genson import SchemaBuilder\n",
    "    import yaml\n",
    "\n",
    "    builder = SchemaBuilder()\n",
    "    builder.add_object(inputDict)\n",
    "    schema = builder.to_schema()\n",
    "    if format_ == \"yaml\":\n",
    "        return yaml.dump(schema)\n",
    "    elif format_ == \"json\":\n",
    "        return schema\n",
    "    elif format_ == \"both\":\n",
    "        return schema, yaml.dump(schema)\n",
    "    else:\n",
    "        return schema, yaml.dump(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: http://json-schema.org/schema#\n",
      "properties:\n",
      "  test:\n",
      "    type: integer\n",
      "required:\n",
      "- test\n",
      "type: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_ = {\"test\": 1}\n",
    "r = genSchema(dict_, format_=\"yaml\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# printYaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def printYaml(input_: dict, returnYaml=False) -> (str, None):\n",
    "    yamlStr: str = yaml.dump(input_)\n",
    "    print(yamlStr)\n",
    "    if returnYaml:\n",
    "        return yamlStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n",
      "  test1: 123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printYaml({\"test\": {\"test1\": 123}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@beartype\n",
    "def loadYaml(path: str, loader=yaml.FullLoader) -> dict:\n",
    "    \"\"\"load yaml string\n",
    "    input:\n",
    "      path:str: path of the data to load\n",
    "    return:\n",
    "      diet of the yaml\n",
    "\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        r = yaml.load(f.read(), Loader=loader)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'test'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"testData/test.yaml\"\n",
    "data = {\"test\": \"test\"}\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(yaml.dump(data))\n",
    "loadYaml(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writeYaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@beartype\n",
    "def writeYaml(path: str, data: dict):\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(yaml.dump(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'test'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"testData/test.yaml\"\n",
    "data = {\"test\": \"test\"}\n",
    "writeYaml(path, data)\n",
    "loadYaml(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hashDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import functools\n",
    "import json\n",
    "import ujson\n",
    "import pickle\n",
    "\n",
    "\n",
    "def hash_dict(func):\n",
    "    \"\"\"Transform mutable dictionnary\n",
    "    Into immutable\n",
    "    Useful to be compatible with cache\n",
    "    \"\"\"\n",
    "\n",
    "    class HDict(dict):\n",
    "        def __hash__(self):\n",
    "            return hash(ujson.dumps(self, sort_keys=True))\n",
    "\n",
    "    #           return hash(tuple(frozenset(sorted(self.items()))))\n",
    "    #           print(self)\n",
    "    #           return hash(hashDict(self))\n",
    "    #             return hash(frozenset(self.items()))\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapped(*args, **kwargs):\n",
    "        args = tuple([HDict(arg) if isinstance(arg, dict) else arg for arg in args])\n",
    "        kwargs = {k: HDict(v) if isinstance(v, dict) else v for k, v in kwargs.items()}\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cachetools.func\n",
    "from beartype import beartype\n",
    "import time\n",
    "\n",
    "\n",
    "@beartype\n",
    "@hash_dict\n",
    "@cachetools.func.ttl_cache(ttl=10)\n",
    "def testFunc(input_: dict) -> dict:\n",
    "    time.sleep(2)\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'test': 'test'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFunc({\"test\": {\"test\": \"test\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2608427765084268190"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(ujson.dumps(({\"test\": {\"test\": \"test\"}}), sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepUpdate\n",
    "\n",
    "merge nested dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import collections\n",
    "\n",
    "\n",
    "def deepUpdate(d, u):\n",
    "    for k, v in u.items():\n",
    "        if isinstance(d, collections.Mapping):\n",
    "            if isinstance(v, collections.Mapping):\n",
    "                r = deepUpdate(d.get(k, {}), v)\n",
    "                d[k] = r\n",
    "            else:\n",
    "                d[k] = u[k]\n",
    "        else:\n",
    "            d = {k: u[k]}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k1': {'k2': {'k3': 3}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepUpdate({\"k1\": 1}, {\"k1\": {\"k2\": {\"k3\": 3}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
